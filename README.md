# Image-Caption-Generator
The project involved developing an advanced image captioning model that leverages deep learning and natural language processing (NLP) techniques. Using the VGG16 model for feature extraction and LSTM networks for sequence generation, the model was trained to automatically generate captions for images. A comprehensive data preprocessing pipeline was implemented to enhance the model's performance, enabling it to produce accurate and contextually relevant descriptions. The model's effectiveness was evaluated using BLEU scores, achieving a BLEU-1 score of 0.516 and a BLEU-2 score of 0.293, reflecting its capability to generate coherent and meaningful captions. This project demonstrates a solid understanding of both NLP and deep learning, showcasing the practical application of AI in automated image captioning.






